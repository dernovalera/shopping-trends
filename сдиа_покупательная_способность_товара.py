# -*- coding: utf-8 -*-
"""Ğ¡Ğ”Ğ˜Ğ ĞŸĞ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-PPnWUY7mdbrDxSZThCezVlIZlTJtFP2

# ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· ÑÑƒĞ¼Ğ¼Ñ‹ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½Ğ¾Ğ¹ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚Ğ¸ (FCN)

Ğ’ ÑÑ‚Ğ¾Ğ¹ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğµ Ğ±ĞµÑ€Ñ‘Ğ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ *shopping_trends.csv* Ğ¸ ÑÑ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸, ĞºĞ¾Ñ‚Ğ¾Ñ€Ğ°Ñ Ğ¿Ñ€ĞµĞ´ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµÑ‚ ÑÑƒĞ¼Ğ¼Ñƒ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°.  
Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½ÑƒÑ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ÑŒ Ğ² TensorFlow/Keras Ğ¸ Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ĞµĞ¼ Ğ´Ğ²Ğµ ĞºÑ€Ğ¸Ğ²Ñ‹Ğµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ: MAE Ğ¸ MSE (loss) Ğ´Ğ»Ñ train Ğ¸ validation.
"""

# Ğ˜Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ñ‹ Ğ¸ Ğ¾Ğ±Ñ‰Ğ¸Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OrdinalEncoder, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models, callbacks, regularizers

import warnings
warnings.filterwarnings("ignore")

RANDOM_STATE = 42
EPOCHS = 200
BATCH_SIZE = 32

tf.keras.utils.set_random_seed(RANDOM_STATE)
np.random.seed(RANDOM_STATE)

"""## Ğ¨Ğ°Ğ³ 1. Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…

Ğ—Ğ´ĞµÑÑŒ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶Ğ°ĞµĞ¼ CSVâ€‘Ñ„Ğ°Ğ¹Ğ» Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¾ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ°Ñ… Ğ¸ ÑĞ¼Ğ¾Ñ‚Ñ€Ğ¸Ğ¼ Ğ¿ĞµÑ€Ğ²Ñ‹Ğµ ÑÑ‚Ñ€Ğ¾ĞºĞ¸ Ñ‚Ğ°Ğ±Ğ»Ğ¸Ñ†Ñ‹.

"""

from google.colab import files
print("ğŸ“‚ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·Ğ¸Ñ‚Ğµ shopping_trends.csv")
uploaded = files.upload()

fname = list(uploaded.keys())[0]
df = pd.read_csv(fname)

print("âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾:", fname, "| shape:", df.shape)
df.head()

"""## Ğ¨Ğ°Ğ³ 2. Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ¸ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ²

- Ğ’ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğµ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ±ĞµÑ€Ñ‘Ğ¼ ÑÑ‚Ğ¾Ğ»Ğ±ĞµÑ† **Purchase Amount (USD)**.  
- ĞÑÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ¾Ğ»Ğ±Ñ†Ñ‹ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ ĞºĞ°Ğº Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸, ĞºÑ€Ğ¾Ğ¼Ğµ **Customer ID** (ID Ğ½Ğµ Ğ½ĞµÑÑ‘Ñ‚ Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸).

"""

# Target (Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ)
target_col = "Purchase Amount (USD)"
y = df[target_col].astype(np.float32).values

# ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸: ÑƒĞ±Ğ¸Ñ€Ğ°ĞµĞ¼ ID Ğ¸ target
X_df = df.drop(columns=["Customer ID", target_col], errors="ignore")

cat_cols = X_df.select_dtypes(include=["object", "category", "bool"]).columns.tolist()
num_cols = X_df.select_dtypes(include=[np.number]).columns.tolist()

print("\nâœ… ĞŸÑ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸:", X_df.shape[1])
print("ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ…:", len(cat_cols))
print("Ğ§Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ñ…:", len(num_cols))

"""## Ğ¨Ğ°Ğ³ 3. Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ½Ğ° train/test Ğ¸ Ğ¿Ñ€ĞµĞ´Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°

- Ğ”ĞµĞ»Ğ¸Ğ¼ Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡Ğ°ÑÑ‰ÑƒÑ Ğ¸ Ñ‚ĞµÑÑ‚Ğ¾Ğ²ÑƒÑ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞ¸ (80/20).  
- ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ğ¼ Ğ² Ñ‡Ğ¸ÑĞ»Ğ° Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ `OrdinalEncoder`.  
- Ğ’ÑĞµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€ÑƒĞµĞ¼ Ñ‡ĞµÑ€ĞµĞ· `StandardScaler`, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑĞµÑ‚ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°Ğ»Ğ°ÑÑŒ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½ĞµĞµ.

"""

# Train/Test split
X_train_df, X_test_df, y_train, y_test = train_test_split(
    X_df, y, test_size=0.2, random_state=RANDOM_STATE
)

# OrdinalEncoder Ğ´Ğ»Ñ ĞºĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ñ…
enc = OrdinalEncoder(handle_unknown="use_encoded_value", unknown_value=-1)
X_train_cat = enc.fit_transform(X_train_df[cat_cols]) if len(cat_cols) else np.zeros((len(X_train_df), 0))
X_test_cat  = enc.transform(X_test_df[cat_cols])      if len(cat_cols) else np.zeros((len(X_test_df), 0))

# Ğ§Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸
X_train_num = X_train_df[num_cols].astype(np.float32).values if len(num_cols) else np.zeros((len(X_train_df), 0), dtype=np.float32)
X_test_num  = X_test_df[num_cols].astype(np.float32).values  if len(num_cols) else np.zeros((len(X_test_df), 0), dtype=np.float32)

# ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½ÑĞµĞ¼
X_train_raw = np.hstack([X_train_num, X_train_cat]).astype(np.float32)
X_test_raw  = np.hstack([X_test_num,  X_test_cat ]).astype(np.float32)

# StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train_raw)
X_test  = scaler.transform(X_test_raw)

print("\nâœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾:")
print("X_train:", X_train.shape, "| X_test:", X_test.shape)

"""## Ğ¨Ğ°Ğ³ 4. ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ° Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚Ğ¸

Ğ¡Ñ‚Ñ€Ğ¾Ğ¸Ğ¼ Ğ¿Ğ¾Ğ»Ğ½Ğ¾ÑĞ²ÑĞ·Ğ½ÑƒÑ Ğ½ĞµĞ¹Ñ€Ğ¾ÑĞµÑ‚ÑŒ (FCN) Ğ´Ğ»Ñ Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ğ¸:

- Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑĞ»Ğ¾Ñ‘Ğ² `Dense` Ñ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸ĞµĞ¹ ReLU;
- `BatchNormalization` Ğ¸ `Dropout` Ğ´Ğ»Ñ ÑÑ‚Ğ°Ğ±Ğ¸Ğ»ÑŒĞ½Ğ¾ÑÑ‚Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ² Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ;
- L2â€‘Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ĞµÑĞ¾Ğ²;
- Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Adam, loss = MSE, Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° = MAE.

"""

# ĞœĞ¾Ğ´ĞµĞ»ÑŒ FCN (Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ)
def build_model(input_dim: int) -> keras.Model:
    l2 = regularizers.l2(1e-4)
    m = models.Sequential([
        layers.Input(shape=(input_dim,)),

        layers.Dense(64, activation="relu", kernel_regularizer=l2),
        layers.BatchNormalization(),
        layers.Dropout(0.20),

        layers.Dense(32, activation="relu", kernel_regularizer=l2),
        layers.BatchNormalization(),
        layers.Dropout(0.20),

        layers.Dense(16, activation="relu", kernel_regularizer=l2),
        layers.Dropout(0.10),

        layers.Dense(1, activation="linear")
    ])
    m.compile(
        optimizer=keras.optimizers.Adam(learning_rate=0.001),
        loss="mse",
        metrics=["mae"]
    )
    return m

model = build_model(X_train.shape[1])
model.summary()

"""## Ğ¨Ğ°Ğ³ 5. ĞĞ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸

Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµĞ¼ Ğ´Ğ²Ğµ Ñ‚ĞµÑ…Ğ½Ğ¸ĞºĞ¸:

- **EarlyStopping** â€“ Ğ¾ÑÑ‚Ğ°Ğ½Ğ°Ğ²Ğ»Ğ¸Ğ²Ğ°ĞµÑ‚ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğµ, ĞµÑĞ»Ğ¸ ĞºĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ½Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿ĞµÑ€ĞµÑÑ‚Ğ°Ñ‘Ñ‚ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ‚ÑŒÑÑ.  
- **ReduceLROnPlateau** â€“ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ ÑˆĞ°Ğ³ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ğ³Ğ´Ğ° valâ€‘loss Ğ²Ñ‹Ñ…Ğ¾Ğ´Ğ¸Ñ‚ Ğ½Ğ° Ğ¿Ğ»Ğ°Ñ‚Ğ¾.

Ğ­Ñ‚Ğ¾ Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ, ÑÑ…Ğ¾Ğ´ÑÑ‰Ğ¸ĞµÑÑ ĞºÑ€Ğ¸Ğ²Ñ‹Ğµ Ğ±ĞµĞ· Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ.

"""

early_stop = callbacks.EarlyStopping(
    monitor="val_loss", patience=25, restore_best_weights=True, verbose=1
)
reduce_lr = callbacks.ReduceLROnPlateau(
    monitor="val_loss", factor=0.5, patience=10, min_lr=1e-5, verbose=1
)

history = model.fit(
    X_train, y_train,
    validation_split=0.2,
    epochs=EPOCHS,
    batch_size=BATCH_SIZE,
    callbacks=[early_stop, reduce_lr],
    verbose=1
)

"""## Ğ¨Ğ°Ğ³ 6. ĞšĞ°Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½Ğ° Ñ‚ĞµÑÑ‚Ğ¾Ğ²Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ

Ğ—Ğ´ĞµÑÑŒ ÑÑ‡Ğ¸Ñ‚Ğ°ĞµĞ¼ Ğ¸Ñ‚Ğ¾Ğ³Ğ¾Ğ²Ñ‹Ğµ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ½Ğ° Ğ¾Ñ‚Ğ»Ğ¾Ğ¶ĞµĞ½Ğ½Ğ¾Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ĞºĞµ:
- MAE â€“ ÑÑ€ĞµĞ´Ğ½ÑÑ Ğ°Ğ±ÑĞ¾Ğ»ÑÑ‚Ğ½Ğ°Ñ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°;
- RMSE â€“ ĞºĞ¾Ñ€ĞµĞ½ÑŒ Ğ¸Ğ· ÑÑ€ĞµĞ´Ğ½ĞµĞºĞ²Ğ°Ğ´Ñ€Ğ°Ñ‚Ğ¸Ñ‡Ğ½Ğ¾Ğ¹ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸;
- RÂ² â€“ Ğ´Ğ¾Ğ»Ñ Ğ¾Ğ±ÑŠÑÑĞ½Ñ‘Ğ½Ğ½Ğ¾Ğ¹ Ğ´Ğ¸ÑĞ¿ĞµÑ€ÑĞ¸Ğ¸ (Ğ½Ğ°ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ñ…Ğ¾Ñ€Ğ¾ÑˆĞ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑŠÑÑĞ½ÑĞµÑ‚ Ğ²Ğ°Ñ€Ğ¸Ğ°Ñ†Ğ¸Ñ Ñ†ĞµĞ»ĞµĞ²Ğ¾Ğ¹ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾Ğ¹).

"""

pred_test = model.predict(X_test, verbose=0).flatten()

mae = mean_absolute_error(y_test, pred_test)
rmse = np.sqrt(mean_squared_error(y_test, pred_test))
r2 = r2_score(y_test, pred_test)

print("\nğŸ“Š TEST Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸ (Ñ€ĞµĞ³Ñ€ĞµÑÑĞ¸Ñ):")
print(f"MAE:  {mae:.3f}")
print(f"RMSE: {rmse:.3f}")
print(f"RÂ²:   {r2:.4f}")

"""## Ğ¨Ğ°Ğ³ 7. Ğ“Ñ€Ğ°Ñ„Ğ¸ĞºĞ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ

ĞĞ° ÑÑ‚Ğ¸Ñ… Ğ³Ñ€Ğ°Ñ„Ğ¸ĞºĞ°Ñ… Ğ²Ğ¸Ğ´Ğ½Ğ¾, ĞºĞ°Ğº Ğ² Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞµ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ:

- MAE Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾ÑÑ‚ĞµĞ¿ĞµĞ½Ğ½Ğ¾ ÑƒĞ¼ĞµĞ½ÑŒÑˆĞ°ĞµÑ‚ÑÑ Ğ¸ ĞºÑ€Ğ¸Ğ²Ñ‹Ğµ Ğ¸Ğ´ÑƒÑ‚ Ñ€ÑĞ´Ğ¾Ğ¼;
- MSE (loss) Ğ½Ğ° Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ñ‚Ğ¾Ğ¶Ğµ Ğ¿Ğ»Ğ°Ğ²Ğ½Ğ¾ ÑƒĞ±Ñ‹Ğ²Ğ°ĞµÑ‚ Ğ¸ Ğ½Ğµ Ñ€Ğ°ÑÑ…Ğ¾Ğ´Ğ¸Ñ‚ÑÑ.

Ğ­Ñ‚Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ñ‚ Ğ¾ Ñ‚Ğ¾Ğ¼, Ñ‡Ñ‚Ğ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ Ğ¸ Ğ½Ğµ Ğ¿ĞµÑ€ĞµĞ¾Ğ±ÑƒÑ‡Ğ°ĞµÑ‚ÑÑ.

"""

epochs = range(1, len(history.history["loss"]) + 1)

fig, axes = plt.subplots(1, 2, figsize=(14, 5))

axes[0].plot(epochs, history.history["mae"], label="ĞĞ±ÑƒÑ‡Ğ°ÑÑ‰Ğ°Ñ MAE", linewidth=2)
axes[0].plot(epochs, history.history["val_mae"], label="Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ MAE", linewidth=2)
axes[0].set_title("MAE Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸")
axes[0].set_xlabel("Ğ­Ğ¿Ğ¾Ñ…Ğ°")
axes[0].set_ylabel("MAE")
axes[0].grid(True, alpha=0.3)
axes[0].legend()

axes[1].plot(epochs, history.history["loss"], label="ĞĞ±ÑƒÑ‡Ğ°ÑÑ‰Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ", linewidth=2)
axes[1].plot(epochs, history.history["val_loss"], label="Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¾Ğ½Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ", linewidth=2)
axes[1].set_title("Ğ¤ÑƒĞ½ĞºÑ†Ğ¸Ñ Ğ¿Ğ¾Ñ‚ĞµÑ€ÑŒ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ Ğ¸ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸")
axes[1].set_xlabel("Ğ­Ğ¿Ğ¾Ñ…Ğ°")
axes[1].set_ylabel("MSE Loss")
axes[1].grid(True, alpha=0.3)
axes[1].legend()

plt.tight_layout()
plt.show()

"""## Ğ¨Ğ°Ğ³ 8. Ğ”ĞµĞ¼Ğ¾Ğ½ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ ĞĞ¡ (HTML-ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ†Ğ°)

ĞĞ¸Ğ¶Ğµ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ÑÑ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğµ HTML-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ (Gradio) Ñ Ñ„Ğ¾Ñ€Ğ¼Ğ¾Ğ¹ Ğ²Ğ²Ğ¾Ğ´Ğ° Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¾Ğ².
ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ· ÑÑƒĞ¼Ğ¼Ñ‹ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ (USD).

"""

# --- HTML-Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ Ğ² Colab Ñ‡ĞµÑ€ĞµĞ· Gradio: ÑÑƒĞ¼Ğ¼Ğ° + ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ ---
!pip -q install gradio

import gradio as gr
import numpy as np
import pandas as pd

# Ğ’ĞĞ–ĞĞ: Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ ĞŸĞĞ¡Ğ›Ğ• Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ»Ğ¸:
# model, enc, scaler, cat_cols, num_cols, df

# -------------------------
# 1) Ğ ÑƒÑÑĞºĞ¸Ğµ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¸ Ğ¿Ğ¾Ğ»ĞµĞ¹
# -------------------------
RU_LABELS = {
    "Age": "Ğ’Ğ¾Ğ·Ñ€Ğ°ÑÑ‚",
    "Gender": "ĞŸĞ¾Ğ»",
    "Category": "ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ñ Ñ‚Ğ¾Ğ²Ğ°Ñ€Ğ°",
    "Item Purchased": "ĞšÑƒĞ¿Ğ»ĞµĞ½Ğ½Ñ‹Ğ¹ Ñ‚Ğ¾Ğ²Ğ°Ñ€",
    "Size": "Ğ Ğ°Ğ·Ğ¼ĞµÑ€",
    "Color": "Ğ¦Ğ²ĞµÑ‚",
    "Season": "Ğ¡ĞµĞ·Ğ¾Ğ½",
    "Location": "Ğ›Ğ¾ĞºĞ°Ñ†Ğ¸Ñ/Ğ³Ğ¾Ñ€Ğ¾Ğ´",

    "Payment Method": "Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ± Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ‹",
    "Shipping Type": "Ğ¢Ğ¸Ğ¿ Ğ´Ğ¾ÑÑ‚Ğ°Ğ²ĞºĞ¸",
    "Preferred Payment Method": "ĞŸÑ€ĞµĞ´Ğ¿Ğ¾Ñ‡Ğ¸Ñ‚Ğ°ĞµĞ¼Ñ‹Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ñ‹",

    "Subscription Status": "ĞŸĞ¾Ğ´Ğ¿Ğ¸ÑĞºĞ° (Ğ´Ğ°/Ğ½ĞµÑ‚)",
    "Discount Applied": "Ğ¡ĞºĞ¸Ğ´ĞºĞ° Ğ¿Ñ€Ğ¸Ğ¼ĞµĞ½ĞµĞ½Ğ°",
    "Promo Code Used": "ĞŸÑ€Ğ¾Ğ¼Ğ¾ĞºĞ¾Ğ´ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½",

    "Previous Purchases": "ĞŸÑ€ĞµĞ´Ñ‹Ğ´ÑƒÑ‰Ğ¸Ğµ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ (ĞºĞ¾Ğ»-Ğ²Ğ¾)",
    "Review Rating": "ĞÑ†ĞµĞ½ĞºĞ° (Ñ€ĞµĞ¹Ñ‚Ğ¸Ğ½Ğ³)",
    "Frequency of Purchases": "Ğ§Ğ°ÑÑ‚Ğ¾Ñ‚Ğ° Ğ¿Ğ¾ĞºÑƒĞ¿Ğ¾Ğº",
}

def ru_label(col_name: str) -> str:
    return RU_LABELS.get(col_name, col_name)

# -------------------------
# 2) ĞŸĞµÑ€ĞµĞ²Ğ¾Ğ´ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ñ… Yes/No Ğ¸ Ğ¿Ğ¾Ğ»Ğ°)
# -------------------------
RU_VALUES = {
    "Gender": {"Male": "ĞœÑƒĞ¶ÑĞºĞ¾Ğ¹", "Female": "Ğ–ĞµĞ½ÑĞºĞ¸Ğ¹"},
    "Subscription Status": {"Yes": "Ğ”Ğ°", "No": "ĞĞµÑ‚"},
    "Discount Applied": {"Yes": "Ğ”Ğ°", "No": "ĞĞµÑ‚"},
    "Promo Code Used": {"Yes": "Ğ”Ğ°", "No": "ĞĞµÑ‚"},
}

def to_ru_value(col, val):
    return RU_VALUES.get(col, {}).get(val, val)

def to_en_value(col, val_ru):
    rev = {v: k for k, v in RU_VALUES.get(col, {}).items()}
    return rev.get(val_ru, val_ru)

# -------------------------
# 3) ĞŸĞ¾Ñ€Ğ¾Ğ³Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¹ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ (Ğ¿Ğ¾ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ñƒ)
# -------------------------
target_col = "Purchase Amount (USD)"
q1 = float(df[target_col].quantile(0.25))
q3 = float(df[target_col].quantile(0.75))

def ability_level(pred_usd: float) -> str:
    if pred_usd < q1:
        return f"ĞĞ¸Ğ·ĞºĞ°Ñ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ°Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ½Ğ¸Ğ¶Ğµ Q1 = ${q1:.2f})"
    elif pred_usd < q3:
        return f"Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ°Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ¼ĞµĞ¶Ğ´Ñƒ Q1=${q1:.2f} Ğ¸ Q3=${q3:.2f})"
    else:
        return f"Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ°Ñ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚ÑŒ (Ğ²Ñ‹ÑˆĞµ Q3 = ${q3:.2f})"

print(f"âœ… ĞŸĞ¾Ñ€Ğ¾Ğ³Ğ¸ ÑƒÑ€Ğ¾Ğ²Ğ½ĞµĞ¹: Q1=${q1:.2f}, Q3=${q3:.2f}")

# -------------------------
# 4) Ğ¡Ğ¿Ğ¸ÑĞºĞ¸ Ğ´Ğ»Ñ Ñ„Ğ¾Ñ€Ğ¼Ñ‹
# -------------------------
cat_choices_raw = {}
for c in cat_cols:
    cat_choices_raw[c] = sorted(df[c].dropna().astype(str).unique().tolist())

num_defaults = {}
for c in num_cols:
    num_defaults[c] = float(pd.to_numeric(df[c], errors="coerce").dropna().mean())

# -------------------------
# 5) ĞŸÑ€ĞµĞ´ÑĞºĞ°Ğ·Ğ°Ğ½Ğ¸Ğµ: ÑÑƒĞ¼Ğ¼Ğ° + ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ
# -------------------------
def predict_purchase_amount_and_level(*inputs):
    data = {}
    idx = 0

    # Ğ§Ğ¸ÑĞ»Ğ¾Ğ²Ñ‹Ğµ
    for c in num_cols:
        data[c] = [float(inputs[idx])]
        idx += 1

    # ĞšĞ°Ñ‚ĞµĞ³Ğ¾Ñ€Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ
    for c in cat_cols:
        val_ru = str(inputs[idx])
        data[c] = [to_en_value(c, val_ru)]
        idx += 1

    row = pd.DataFrame(data)

    # ĞŸÑ€ĞµĞ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¸Ğ½Ğ³ ĞºĞ°Ğº Ğ² Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ğ¸
    X_cat = enc.transform(row[cat_cols]) if len(cat_cols) else np.zeros((1, 0), dtype=np.float32)
    X_num = row[num_cols].astype(np.float32).values if len(num_cols) else np.zeros((1, 0), dtype=np.float32)

    X_raw = np.hstack([X_num, X_cat]).astype(np.float32)
    X_scaled = scaler.transform(X_raw)

    pred = float(model.predict(X_scaled, verbose=0).flatten()[0])
    pred_round = float(round(pred, 2))

    level = ability_level(pred_round)
    return pred_round, level

# -------------------------
# 6) UI
# -------------------------
inputs_ui = []

for c in num_cols:
    inputs_ui.append(gr.Number(label=ru_label(c), value=num_defaults.get(c, 0.0)))

for c in cat_cols:
    raw = cat_choices_raw[c]
    ru_list = [to_ru_value(c, v) for v in raw]
    default = ru_list[0] if len(ru_list) else ""
    inputs_ui.append(gr.Dropdown(choices=ru_list, value=default, label=ru_label(c)))

demo = gr.Interface(
    fn=predict_purchase_amount_and_level,
    inputs=inputs_ui,
    outputs=[
        gr.Number(label="ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· ÑÑƒĞ¼Ğ¼Ñ‹ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ (USD)"),
        gr.Textbox(label="ĞÑ†ĞµĞ½ĞºĞ° Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸", lines=2)
    ],
    title="ĞŸÑ€Ğ¾Ğ³Ğ½Ğ¾Ğ· Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ (FCN / TensorFlow)",
    description="ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ñ€Ğ¾Ğ³Ğ½Ğ¾Ğ·Ğ¸Ñ€ÑƒĞµÑ‚ ÑÑƒĞ¼Ğ¼Ñƒ Ğ¿Ğ¾ĞºÑƒĞ¿ĞºĞ¸ (USD) Ğ¸ Ğ¿ĞµÑ€ĞµĞ²Ğ¾Ğ´Ğ¸Ñ‚ ĞµÑ‘ Ğ² ÑƒÑ€Ğ¾Ğ²ĞµĞ½ÑŒ Ğ¿Ğ¾ĞºÑƒĞ¿Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ¹ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾ ĞºĞ²Ğ°Ñ€Ñ‚Ğ¸Ğ»ÑĞ¼ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚Ğ° (Q1/Q3)."
)

demo.launch(share=True)